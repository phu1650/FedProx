{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2fbba861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad, backward\n",
    "from torchvision import datasets , transforms\n",
    "from torchvision.transforms import Compose\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bf8d8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNetwork, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "346bb5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/workspace/nvflare/FedProx/Data'\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "transforms = Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])\n",
    "BATCH_SIZE = 4\n",
    "EPOCH = 10\n",
    "LR = 1e-2\n",
    "model_pth = '/workspace/nvflare/FedProx/model/'\n",
    "model_name= 'model_second_half_tune_param.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63b4df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ds = datasets.CIFAR10(root=data_path, transform=transforms, download=True, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b3fbf54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half = list(range(0, len(ds)//2))\n",
    "second_half = list(range(len(ds)//2, len(ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3d7276ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Subset(ds, second_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "901ed6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(ds))\n",
    "y = []\n",
    "for i in range(len(ds)):\n",
    "    y.append(ds[i][1])\n",
    "# print(y[0])\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.15, stratify=y)\n",
    "train_ds = Subset(dataset, train_indices)\n",
    "val_ds = Subset(dataset, val_indices)\n",
    "train_data_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_data_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "n_iterations = len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "675c8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNetwork().to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "883f1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "          data_loader, \n",
    "          loss_fn,\n",
    "          opimizer,\n",
    "          n_example):\n",
    "   \n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct = 0 \n",
    "    for step, (data, target) in enumerate(data_loader):\n",
    "        img = data.to(DEVICE)\n",
    "        targets = target.to(DEVICE)\n",
    "        out1 = model( img)\n",
    "        _,pred = torch.max(out1, dim = 1)\n",
    "        correct += torch.sum(pred == targets)\n",
    "        loss1 =  loss_fn(out1, targets)\n",
    "        losses.append(loss1.item() )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "    return correct / n_example , np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bd27a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    " def val_model(model, \n",
    "          data_loader, \n",
    "          loss_fn,\n",
    "          n_example):\n",
    "   \n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct = 0 \n",
    "    with torch.no_grad():\n",
    "        for step, (data, target) in enumerate(data_loader):\n",
    "            img = data.to(DEVICE)\n",
    "            targets = target.to(DEVICE)\n",
    "            out1 = model( img)\n",
    "            _,pred = torch.max(out1, dim = 1)\n",
    "            correct += torch.sum(pred == targets)\n",
    "            loss1 =  loss_fn(out1, targets)\n",
    "            losses.append(loss1.item() )\n",
    "\n",
    "            \n",
    "    return correct / n_example , np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "923c1d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "===============\n",
      "Train Accuracy : 0.2691764831542969 Train Loss : 1.9668471538681735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▍                                                                           | 1/10 [00:18<02:50, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.2837333381175995 Val Loss : 2.081955168960191\n",
      "Epoch 2 / 10\n",
      "===============\n",
      "Train Accuracy : 0.4217882454395294 Train Loss : 1.59112768908151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 2/10 [00:38<02:32, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.4477333426475525 Val Loss : 1.555730192995529\n",
      "Epoch 3 / 10\n",
      "===============\n",
      "Train Accuracy : 0.474823534488678 Train Loss : 1.4549611197557015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▏                                                          | 3/10 [00:57<02:13, 19.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.48399999737739563 Val Loss : 1.4383855926424964\n",
      "Epoch 4 / 10\n",
      "===============\n",
      "Train Accuracy : 0.5142588019371033 Train Loss : 1.3612784305445425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▌                                                  | 4/10 [01:16<01:53, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.5058666467666626 Val Loss : 1.3963114606387326\n",
      "Epoch 5 / 10\n",
      "===============\n",
      "Train Accuracy : 0.5389176607131958 Train Loss : 1.2898450201819358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████                                          | 5/10 [01:34<01:34, 18.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.525866687297821 Val Loss : 1.3519710938511753\n",
      "Epoch 6 / 10\n",
      "===============\n",
      "Train Accuracy : 0.5607059001922607 Train Loss : 1.22614872843201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████▍                                 | 6/10 [01:53<01:15, 18.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.4898666739463806 Val Loss : 1.484388658359869\n",
      "Epoch 7 / 10\n",
      "===============\n",
      "Train Accuracy : 0.580752968788147 Train Loss : 1.17815859408328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████▊                         | 7/10 [02:12<00:56, 18.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.5112000107765198 Val Loss : 1.3999307463799457\n",
      "Epoch 8 / 10\n",
      "===============\n",
      "Train Accuracy : 0.6053176522254944 Train Loss : 1.1137969847547677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████▏                | 8/10 [02:31<00:37, 18.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.4994666576385498 Val Loss : 1.5617254828053242\n",
      "Epoch 9 / 10\n",
      "===============\n",
      "Train Accuracy : 0.619105875492096 Train Loss : 1.0695342580356095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████▌        | 9/10 [02:50<00:18, 18.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.5095999836921692 Val Loss : 1.4733933130545276\n",
      "Epoch 10 / 10\n",
      "===============\n",
      "Train Accuracy : 0.6332706212997437 Train Loss : 1.0288435523747927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [03:09<00:00, 18.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.5226666927337646 Val Loss : 1.4532176851670244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bestacc = -1\n",
    "n = 0 \n",
    "for epoch in tqdm(range(EPOCH)):\n",
    "    print(f'Epoch {epoch + 1} / {EPOCH}')\n",
    "    print(\"=\" *15)\n",
    "    train_acc,train_loss = train_model(model, train_data_loader ,loss_fn, optimizer  , len(train_ds)   )\n",
    "    print(f'Train Accuracy : {train_acc} Train Loss : {train_loss}')\n",
    "    val_acc,val_loss = val_model(model, val_data_loader ,loss_fn  , len( val_ds)   )\n",
    "    print(f'Val Accuracy : {val_acc} Val Loss : {val_loss}')\n",
    "    if bestacc < val_acc:\n",
    "        bestacc = val_acc\n",
    "        torch.save(model,model_pth + model_name)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "588e58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pth = '/workspace/nvflare/FedProx/model/'\n",
    "# model_name= 'model_second_half_tune_param.pth'\n",
    "# torch.save(model,model_pth + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0d5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c1bc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
